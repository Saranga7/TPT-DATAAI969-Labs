{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Skin lesion classification"
      ],
      "metadata": {
        "id": "Ao3Aj_ZSzwQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deadline**: Upload this notebook (rename it as 'TP1-ML-YOUR-SURNAME.ipynb') to Ecampus/Moodle before the deadline.\n"
      ],
      "metadata": {
        "id": "TD2Mt3JRz1VY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Context**\n",
        "A skin lesion is defined as a superficial growth or patch of the skin that is visually different and/or has a different texture than its surrounding area. Skin lesions, such as moles or birthmarks, can degenerate and become melanoma, one of the deadliest skin cancer. Its incidence has been increasing during the last decades, especially in the areas mostly populated by white people.\n",
        "\n",
        "The most effective treatment is an early detection followed by surgical excision. This is why several approaches for melanoma detection have been proposed in the last years (non-invasive computer-aided diagnosis (CAD) ).\n",
        "\n",
        "**Data**\n",
        "You will have at your disposal the ISIC 2017 dataset (https://challenge.isic-archive.com/data/#2017) already pre-processed, resized and quality checked. It is divided into Training (N=2000), Validation (N=150) and Test (N=600) sets.\n",
        "\n",
        "**Goal**\n",
        "The goal of this practical session is to classify images of skin lesions as either benign (nevus or seborrheic_keratosis) or melanoma (binary classification) using machine and deep learning algorithms.\n",
        "\n",
        "In the first part of the TP, you will manually compute some features relevant to the skin lesion classification (feature engineering) and then classify images using \"classical\" ML algorithms such as, logistic regression, SVM and Random Forests.\n",
        "\n",
        "In the second part, you will test the features learnt with Deep Learning algorithms. You will first train from scratch well-known CNN architectures (VGG, ResNet, DenseNet, etc..) and then leverage the representations learnt by these networks on a pre-training from Imagenet (fine-tuning, full-restimation).\n",
        "\n",
        "Please complete the code where you see **\"XXXXXXXXX\"** and answer the **Questions**\n"
      ],
      "metadata": {
        "id": "12KVxsLdz83m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering\n",
        "\n",
        "Many features have been proposed for Skin lesion classification. Among the most used ones, there is the so-called ABCD rule whose features describie four important characteristics of the skin lesion: Asymmetry, Border irregularity, Colour(and Texture) and Dimension (and Geometry).\n",
        "\n",
        "To compute these features, you will have at your disposal the *manual segmentation* of the skin lesions and you could follow, for instance, *Ganster et al. 'Automated melanoma recognition', IEEE TMI, 2001* and *Zortea et al. 'Performance of a dermoscopy-based computer vision system for the diagnosis of pigmented skin lesions compared with visual evaluation by experienced dermatologists', Artificial Intelligence in Medicine, 2014*.\n",
        "\n",
        "Other works can be found in the literature."
      ],
      "metadata": {
        "id": "bJPUtAA3reXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the ML part, you can use the CPU server (no need for GPU here)"
      ],
      "metadata": {
        "id": "TpXqDzsxrsEw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQkZ88OILkWb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage.io import imread\n",
        "from skimage.io import imsave\n",
        "from skimage.transform import resize\n",
        "from skimage import color\n",
        "from skimage import measure\n",
        "from skimage import transform\n",
        "from skimage.color import rgb2gray\n",
        "from scipy import ndimage\n",
        "from scipy import stats\n",
        "from scipy.stats import gaussian_kde\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import AxesGrid\n",
        "import torch\n",
        "import glob\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "  !pip install gdown==4.6.0 # with the following versions, there is an error\n",
        "except:\n",
        "  IN_COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can either download the data from my Google Drive or work locally."
      ],
      "metadata": {
        "id": "2vUnlFkU3SGr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0r--DZ47OJ2"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "  print(\"you are using google colab\")\n",
        "  import gdown\n",
        "  !mkdir ./data\n",
        "  gdown.download(id=\"1iH5hkRN0wCgGklUN5df9u2Ue3UXAR4xZ\", output='./data/TrainCropped.zip', quiet=False)\n",
        "  !unzip -qu \"./data/TrainCropped.zip\" -d \"./data\"\n",
        "  gdown.download(id=\"1lyRZuV9UST55AEqwSy4mqMmh5yHGI1FM\", output='./data/TestCropped.zip', quiet=False)\n",
        "  !unzip -qu \"./data/TestCropped.zip\" -d \"./data\"\n",
        "  gdown.download(id=\"1RLJOmqAnHCgiJ7qShQurpxNaRhjjPpJb\", output='./data/ValCropped.zip', quiet=False)\n",
        "  !unzip -qu \"./data/ValCropped.zip\" -d \"./data\"\n",
        "  !rm -rf ./data/TrainCropped.zip\n",
        "  !rm -rf ./data/TestCropped.zip\n",
        "  !rm -rf ./data/ValCropped.zip\n",
        "  path='./data/'\n",
        "else:\n",
        "  print('You are NOT using colab')\n",
        "  # we assume that folders of data are in the same folder as this jupyter notebook\n",
        "  path='' # if you change this path , you should also change idTRain, idVal and idTest\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If there is an error (might happen with gdown) please upload the three files manually.\n",
        "Follow the following instructions:\n",
        "- go to the folder symbol on the left of your screen\n",
        "- click on the three vertical dots on the 'data' folder\n",
        "- upload (importer in french) the three folders\n",
        "That's it !"
      ],
      "metadata": {
        "id": "b2z2gHwk4tIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if IN_COLAB:\n",
        "#   !unzip -qu \"./data/TrainCropped.zip\" -d \"./data\"\n",
        "#   !unzip -qu \"./data/TestCropped.zip\" -d \"./data\"\n",
        "#   !unzip -qu \"./data/ValCropped.zip\" -d \"./data\"\n",
        "#   !rm -rf ./data/TrainCropped.zip\n",
        "#   !rm -rf ./data/TestCropped.zip\n",
        "#   !rm -rf ./data/ValCropped.zip\n",
        "#   path='./data/'"
      ],
      "metadata": {
        "id": "nFcmZwt_3c1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load the data."
      ],
      "metadata": {
        "id": "UcVOKS5t3gnA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YidL3vd9pNf3"
      },
      "outputs": [],
      "source": [
        "pathTrain=glob.glob(path + \"TrainCropped/*.jpg\")\n",
        "print(pathTrain)\n",
        "idTrain=np.copy(pathTrain)\n",
        "if IN_COLAB:\n",
        "    for i in np.arange(len(idTrain)): idTrain[i]=idTrain[i][20:-4]\n",
        "else:\n",
        "    for i in np.arange(len(idTrain)): idTrain[i]=idTrain[i][13:-4]\n",
        "#print(idTrain)\n",
        "print('There are', len(idTrain), 'Train images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKnL44cKqEl3"
      },
      "outputs": [],
      "source": [
        "pathVal=glob.glob(path + \"ValCropped/*.jpg\")\n",
        "idVal=np.copy(pathVal)\n",
        "if IN_COLAB:\n",
        "    for i in np.arange(len(idVal)): idVal[i]=idVal[i][18:-4]\n",
        "else:\n",
        "    for i in np.arange(len(idVal)): idVal[i]=idVal[i][11:-4]\n",
        "#print(idVal)\n",
        "print('There are', len(idVal) , 'Validation images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJLmMYRgpQFk"
      },
      "outputs": [],
      "source": [
        "pathTest=glob.glob(path + \"TestCropped/*.jpg\")\n",
        "idTest=np.copy(pathTest)\n",
        "if IN_COLAB:\n",
        "    for i in np.arange(len(idTest)): idTest[i]=idTest[i][19:-4]\n",
        "else:\n",
        "    for i in np.arange(len(idTest)): idTest[i]=idTest[i][12:-4]\n",
        "#print(idTest)\n",
        "print('There are', len(idTest) , 'Test images')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then plot an image with the related mask and contour."
      ],
      "metadata": {
        "id": "ft-ExOfl3jmJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP4EOguOqLkK"
      },
      "outputs": [],
      "source": [
        "name_im = idTrain[10]\n",
        "filename = path + 'TrainCropped/{}.jpg'.format(name_im)\n",
        "image = imread(filename)\n",
        "filename_Segmentation = path + 'TrainCropped/{}seg.png'.format(name_im)\n",
        "image_Segmentation = imread(filename_Segmentation) # Value 0 or 255\n",
        "image_Segmentation_boolean = (image_Segmentation/255).astype(np.uint8) # To get uint16\n",
        "image_Segmentation_expand = np.expand_dims(image_Segmentation_boolean, axis=2)\n",
        "image_mul_mask = (image_Segmentation_expand*image)\n",
        "contours = cv2.findContours(image_Segmentation_boolean, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
        "contour = list(contours[0])\n",
        "contour = np.squeeze(np.asarray(contour))\n",
        "\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "grid = AxesGrid(fig, 111,\n",
        "                nrows_ncols = (1, 3),\n",
        "                axes_pad = 0.5)\n",
        "grid[0].imshow(image)\n",
        "grid[0].scatter(contour[:,0],contour[:,1])\n",
        "#grid[0].axis('off')\n",
        "grid[0].set_title(\"Original image\")\n",
        "grid[1].imshow(image_Segmentation_boolean)\n",
        "#grid[1].axis('off')\n",
        "grid[1].set_title(\"Mask\")\n",
        "grid[2].imshow(image_mul_mask)\n",
        "#grid[2].axis('off')\n",
        "grid[2].set_title(\"Image with mask\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlsgMiwcgIQ0"
      },
      "source": [
        "##Manual Feature Engineering\n",
        "\n",
        "In this part, you will have to manually compute features relevant to the skin lesion classification. You can, for instance, implement the features described in [1] or in other papers.\n",
        "\n",
        "**TODO**: Implement at least 10 features belonging to at least 3 classes of the ABCD rule, namely:\n",
        "- Asymmetry\n",
        "- Border\n",
        "- Color (and Texture)\n",
        "- Dimension (and Geometry)\n",
        "\n",
        "**Please note the overall time (reading papers + implementation + computation) for computing the features. You will need it in the next part of the practical session.**\n",
        "\n",
        "**This part counts for half of the grade of this TP**\n",
        "\n",
        "[1] M. Zortea et al. \"Performance of a dermoscopy-based computer vision system for the diagnosis of pigmented skin lesions compared with visual evaluation by experienced dermatologists\". Artificial Intelligence in Medicine. 2014"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XXXXXXXXXXXXX\n",
        "# Add here your code"
      ],
      "metadata": {
        "id": "BU9FD5wuyeUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Metadata and Target values\n",
        "\n",
        "You have at your disposal also two metadata, the age and the sex. If you want, you can use them as features in the classification but be careful ! There are missing values\n",
        "\n",
        "We also load the target values (0 for benign and 1 for melanoma)"
      ],
      "metadata": {
        "id": "ngOYRqe9h-N1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3qeLjuB9F84"
      },
      "outputs": [],
      "source": [
        "Metatrain = pd.read_csv('./data/TrainCropped/ISIC-2017_Training_Data_metadata.csv')\n",
        "print(Metatrain.head(10))\n",
        "Groundtrain = pd.read_csv('./data/TrainCropped/ISIC-2017_Training_Part3_GroundTruth.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqB5ZLXeyo3q"
      },
      "outputs": [],
      "source": [
        "Ytrain=np.zeros(len(idTrain))\n",
        "for i in range(len(idTrain)):\n",
        "  name=idTrain[i]\n",
        "  index=Groundtrain[\"image_id\"].str.find(name)\n",
        "  max_index = index.argmax()\n",
        "  Ytrain[i]=int(Groundtrain[\"melanoma\"][max_index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crTO9h5x5Fla"
      },
      "outputs": [],
      "source": [
        "Metaval = pd.read_csv('./data/ValCropped/ISIC-2017_Validation_Data_metadata.csv')\n",
        "Groundval = pd.read_csv('./data/ValCropped/ISIC-2017_Validation_Part3_GroundTruth.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7QFUNEtys_L"
      },
      "outputs": [],
      "source": [
        "Yval=np.zeros(len(idVal))\n",
        "for i in range(len(idVal)):\n",
        "  name=idVal[i]\n",
        "  index=Groundval[\"image_id\"].str.find(name)\n",
        "  max_index = index.argmax()\n",
        "  Yval[i]=int(Groundval[\"melanoma\"][max_index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgSzrYNS5dnH"
      },
      "outputs": [],
      "source": [
        "Metatest = pd.read_csv('./data/TestCropped/ISIC-2017_Test_v2_Data_metadata.csv')\n",
        "Groundtest = pd.read_csv('./data/TestCropped/ISIC-2017_Test_v2_Part3_GroundTruth.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZjgOfVqytE_"
      },
      "outputs": [],
      "source": [
        "Ytest=np.zeros(len(idTest))\n",
        "for i in range(len(idTest)):\n",
        "  name=idTest[i]\n",
        "  index=Groundtest[\"image_id\"].str.find(name)\n",
        "  max_index = index.argmax()\n",
        "  Ytest[i]=int(Groundtest[\"melanoma\"][max_index])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standard Machine Learning Prediction\n",
        "\n",
        "In this part, you will use standard ML algorithms (such as logistic regression, SVM and Random Forests) on the features you previously computed.\n",
        "Before starting, you should look at the data and check the proportion of classes.\n",
        "Two hints:\n",
        "- in sklearn you can use *class_weight='balanced'* when calling a ML method\n",
        "- it exists a very interesting library called *imblearn* (e.g., from imblearn.over_sampling import ADASYN)"
      ],
      "metadata": {
        "id": "d91VC-_9hxxH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsUmL5Le5dFH"
      },
      "outputs": [],
      "source": [
        "np.random.seed(seed=666)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-trained features**: for the next part, you can either use your own features or download a pre-computed set of features."
      ],
      "metadata": {
        "id": "ntKGzKoTyelN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels=['f1_asym','f2_asym','f5_asym','f6_asym','f7_bord','f8_bord','f9_bord','f10_color','f11_color','f12_color','f13_color','f14_color','f15_color','f16_color','f17_color','f18_color','meanR','stdR','meanG','stdG','meanB','stdB','maxR','maxG','maxB','Area','Ecc','Diam','Ratio','Perim','f21_geom','f22_geom','f23_geom']"
      ],
      "metadata": {
        "id": "WHqVbwpRiX2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./data\n",
        "gdown.download(id=\"1ELg93G9jHeJOhCGBZ35HFs3NZr5Inj_j\", output='./data/X_train_eng.npy', quiet=False)\n",
        "train_computation_time=115 # in minute"
      ],
      "metadata": {
        "id": "q8rPw9Daem5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdown.download(id=\"10sr56q1CEro7HPgQjYo0eVniGNA5og5H\", output='./data/X_val_eng.npy', quiet=False)\n",
        "test_computation_time=12 # in minute"
      ],
      "metadata": {
        "id": "HNAo6O3ykUog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./data\n",
        "gdown.download(id=\"1RbONb3WyG-CGt6SSi124TSXfkiCzb6-D\", output='./data/X_test_eng.npy', quiet=False)\n",
        "test_computation_time=38 # in minute"
      ],
      "metadata": {
        "id": "eW88mbrOhgUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXEYzCJfytJg"
      },
      "outputs": [],
      "source": [
        "Xtrain=np.load('./data/X_train_eng.npy')\n",
        "Xtest=np.load('./data/X_test_eng.npy')\n",
        "Xval=np.load('./data/X_val_eng.npy')\n",
        "\n",
        "N,M=Xtrain.shape\n",
        "print('Number of images: {0}; Number of features per image: {1}'.format(N,M))\n",
        "print('Number of healthy nevus: {0}; Number of melanoma: {1}'.format(N-np.sum(Ytrain), np.sum(Ytrain)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XXXXXXXXXXXXX\n",
        "# Add here your code"
      ],
      "metadata": {
        "id": "xMB9FkmfzUcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question**: An important point in medical imaging is the explicability. Can you find the most important and discriminative features ? If yes, how ? Hint: random forest has a very interesting function...  "
      ],
      "metadata": {
        "id": "S7z5wPURwlle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XXXXXXXXXXXXX\n",
        "# Add here your code"
      ],
      "metadata": {
        "id": "GWSqWoOyzZTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you should have a final ML model with a generalization performance on the Test Set.\n",
        "\n",
        "**Question**: Are you satisfied ? How long did it take to compute and evaluate the manually engineered features ? If you are not satisfied, what are the main problems ? Besides Deep Learning, could you do something to improve the results (if you had more time?)"
      ],
      "metadata": {
        "id": "UCYgGs368yJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XXXXXXXXXXXXX"
      ],
      "metadata": {
        "id": "tszK3r4ZzaSW"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "d91VC-_9hxxH"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}