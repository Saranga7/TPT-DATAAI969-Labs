{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhPdJIi2Nbd2"
      },
      "source": [
        "## Rotation Prediction\n",
        "In [1], authors propose to predict the geometric transformation applied to the entire image\n",
        "\n",
        "![](https://drive.google.com/uc?id=1eHXLH-N_6uMGRzdf1Wjnga26qlS5-FRv)\n",
        "\n",
        "They propose to use rotations by 0, 90, 180, 270 degrees as trasformations.\n",
        "\n",
        "[1] S. Gidaris et al. “Unsupervised Representation Learning by Predicting Image Rotations”. In: ICLR. 2018."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtbT2Xzex_js"
      },
      "source": [
        "Let's load all libraries, we will use pytorch and pytorch vision, and check whether we are using CPU or GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LnJlAFB8jfv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "torch.manual_seed(42) # Setting the seed\n",
        "\n",
        "## Torchvision\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import STL10\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "## Plot Options\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib_inline.backend_inline\n",
        "import seaborn as sns\n",
        "plt.set_cmap(\"cividis\")\n",
        "%matplotlib inline\n",
        "sns.set()\n",
        "\n",
        "# save/load models\n",
        "import torch\n",
        "import gdown\n",
        "\n",
        "# In this notebook, we use data loaders with heavier computational processing. It is recommended to use as many\n",
        "# workers as possible in a data loader, which corresponds to the number of CPU cores\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.determinstic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Ensure that you are using GPU and all CPU workers\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device:\", device)\n",
        "print(\"Number of workers:\", NUM_WORKERS)\n",
        "\n",
        "# For reproducibility\n",
        "np.random.seed(666)\n",
        "torch.manual_seed(666)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABAd7xO_qA41"
      },
      "source": [
        "As Dataset, we will use the STL-10 dataset (https://cs.stanford.edu/~acoates/stl10/).\n",
        "It is an image recognition dataset for developing self-supervised and unsupervised feature learning, deep learning algorithms. It is inspired by the CIFAR-10 dataset but with some modifications. In particular, each class has fewer labeled training examples than in CIFAR-10, but a very large set of unlabeled examples is provided.\n",
        "\n",
        "Overview of the dataset:\n",
        "- 10 classes: airplane, bird, car, cat, deer, dog, horse, monkey, ship, truck.\n",
        "- Images are 96x96 pixels, color.\n",
        "- 5000 training images (10 pre-defined folds), 8000 test images.\n",
        "- 100000 unlabeled images. These examples are extracted from a similar but broader distribution of images. For instance, it contains other types of animals (bears, rabbits, etc.) and vehicles (trains, buses, etc.) in addition to the ones in the labeled set.\n",
        "- Images were acquired from labeled examples on $ImageNet$.\n",
        "\n",
        "Pytorch proposes two practical data primitives, called DataSet and DataLoader, to handle datasets for pre-processing and training.\n",
        "There are many data-sets pre-loaded, such as STL-10. For more info: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "\n",
        "In particular, we can easily compose several data-augmentations (transformations), that are automatically applied to the images of the dataset. Here we have an exemple with the transformations used in [1].\n",
        "\n",
        "We will use these transformations in the following."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question**: What's the size of the images after the transformations ? We have two different transformations, one for Training and one for Testing. Why in your opinion ?"
      ],
      "metadata": {
        "id": "_YZC0ztrNBLc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXhGEmnT9voP"
      },
      "outputs": [],
      "source": [
        "transformTrain = transforms.Compose([\n",
        "         transforms.RandomResizedCrop(224),\n",
        "         transforms.RandomHorizontalFlip(),\n",
        "         transforms.ToTensor(),\n",
        "         transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) # these are the average and std from ImageNet\n",
        "         ])\n",
        "\n",
        "transformTest = transforms.Compose([\n",
        "          transforms.Resize(256),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "         ])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use only the training and test datasets (few images) to speed up computations."
      ],
      "metadata": {
        "id": "NfJXFpnkdoCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = STL10(root=\"./data\", split=\"train\", download=True, transform=transformTrain)\n",
        "test_dataset = STL10(root=\"./data\", split=\"test\", download=True, transform=transformTest)"
      ],
      "metadata": {
        "id": "aMgSc4Egdna_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kioo1xFkQVRa"
      },
      "source": [
        "Let's have a look at the training and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMXiU1qX2dqu"
      },
      "outputs": [],
      "source": [
        "# Train dataset\n",
        "classes=train_dataset.classes\n",
        "print(classes)\n",
        "print('Number images in Train dataset:' , len(train_dataset)) # retrieve length of dataset\n",
        "print(train_dataset[3][0].shape) # this is one image\n",
        "print(train_dataset[3][1]) # this is a label\n",
        "\n",
        "#Test dataset\n",
        "print('Number images in Test dataset:' ,len(test_dataset))\n",
        "print(test_dataset[0][0].shape) # this is one image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uGNhkPQx_jy"
      },
      "source": [
        "Let's plot few images to see how are they. We need to de-normalize images using the statics of ImageNet (images come from ImageNet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIH9otn52ZR1"
      },
      "outputs": [],
      "source": [
        "def imshowSTL10(dataset,rows=3,columns=3,figsize=(8, 8)):\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    for i in range(1, rows*columns+1):\n",
        "      img = dataset[i][0]\n",
        "\n",
        "      #REMOVE NORMALIZATION\n",
        "      mean = torch.tensor([0.485, 0.456, 0.406])\n",
        "      std = torch.tensor([0.229, 0.224, 0.225])\n",
        "      unnormalize = transforms.Normalize((-mean / std).tolist(), (1.0 / std).tolist())\n",
        "      # Clip values to range [0,1] -> possible rounding errors during normalization\n",
        "      img = np.clip(unnormalize(img).numpy(),0,1)\n",
        "\n",
        "      label = dataset[i][1]\n",
        "      fig.add_subplot(rows, columns, i)\n",
        "      plt.title(dataset.classes[label])\n",
        "      plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "      plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KmQg476Jqtl"
      },
      "outputs": [],
      "source": [
        "imshowSTL10(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1fSH4ONZkSp"
      },
      "source": [
        "Now it's time to implement our network.\n",
        "\n",
        "Since STL10 comes from ImageNet, we take the same network proposed for ImageNet in [1], inspired by AlexNet.\n",
        "\n",
        "Here you can find the (modified) version of AlexNet (e.g., no DropOut) borrowed from the GitHub of the authors.  \n",
        "\n",
        "**Question**: Choose an approriate value for num_classes and explain why"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5toYrq0ZOFJ"
      },
      "outputs": [],
      "source": [
        "# Code borrowed from https://github.com/gidariss/FeatureLearningRotNet\n",
        "# AlexNet\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet, self).__init__()\n",
        "        num_classes = XXXXXXXXXXXXXXXX\n",
        "\n",
        "        conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        conv2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        pool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        conv3 = nn.Sequential(\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        conv4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        conv5 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        pool5 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "        num_pool5_feats = 6 * 6 * 256\n",
        "        fc_block = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(num_pool5_feats, 4096, bias=False),\n",
        "            nn.BatchNorm1d(4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 4096, bias=False),\n",
        "            nn.BatchNorm1d(4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        classifier = nn.Sequential(\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "        self._feature_blocks = nn.ModuleList([\n",
        "            conv1,\n",
        "            pool1,\n",
        "            conv2,\n",
        "            pool2,\n",
        "            conv3,\n",
        "            conv4,\n",
        "            conv5,\n",
        "            pool5,\n",
        "            fc_block,\n",
        "            classifier,\n",
        "        ])\n",
        "        self.all_feat_names = [\n",
        "            'conv1',\n",
        "            'pool1',\n",
        "            'conv2',\n",
        "            'pool2',\n",
        "            'conv3',\n",
        "            'conv4',\n",
        "            'conv5',\n",
        "            'pool5',\n",
        "            'fc_block',\n",
        "            'classifier',\n",
        "        ]\n",
        "        assert(len(self.all_feat_names) == len(self._feature_blocks))\n",
        "\n",
        "    def _parse_out_keys_arg(self, out_feat_keys):\n",
        "\n",
        "        # By default return the features of the last layer / module.\n",
        "        out_feat_keys = [self.all_feat_names[-1],] if out_feat_keys is None else out_feat_keys\n",
        "\n",
        "        if len(out_feat_keys) == 0:\n",
        "            raise ValueError('Empty list of output feature keys.')\n",
        "        for f, key in enumerate(out_feat_keys):\n",
        "            if key not in self.all_feat_names:\n",
        "                raise ValueError('Feature with name {0} does not exist. Existing features: {1}.'.format(key, self.all_feat_names))\n",
        "            elif key in out_feat_keys[:f]:\n",
        "                raise ValueError('Duplicate output feature key: {0}.'.format(key))\n",
        "\n",
        "        # Find the highest output feature in `out_feat_keys\n",
        "        max_out_feat = max([self.all_feat_names.index(key) for key in out_feat_keys])\n",
        "\n",
        "        return out_feat_keys, max_out_feat\n",
        "\n",
        "    def forward(self, x, out_feat_keys=None):\n",
        "        \"\"\"Forward an image `x` through the network and return the asked output features.\n",
        "        Args:\n",
        "          x: input image.\n",
        "          out_feat_keys: a list/tuple with the feature names of the features\n",
        "                that the function should return. By default the last feature of\n",
        "                the network is returned.\n",
        "        Return:\n",
        "            out_feats: If multiple output features were asked then `out_feats`\n",
        "                is a list with the asked output features placed in the same\n",
        "                order as in `out_feat_keys`. If a single output feature was\n",
        "                asked then `out_feats` is that output feature (and not a list).\n",
        "        \"\"\"\n",
        "        out_feat_keys, max_out_feat = self._parse_out_keys_arg(out_feat_keys)\n",
        "        out_feats = [None] * len(out_feat_keys)\n",
        "\n",
        "        feat = x\n",
        "        for f in range(max_out_feat+1):\n",
        "            feat = self._feature_blocks[f](feat)\n",
        "            key = self.all_feat_names[f]\n",
        "            if key in out_feat_keys:\n",
        "                out_feats[out_feat_keys.index(key)] = feat\n",
        "\n",
        "        out_feats = out_feats[0] if len(out_feats)==1 else out_feats\n",
        "        return out_feats\n",
        "\n",
        "    def get_L1filters(self):\n",
        "        convlayer = self._feature_blocks[0][0]\n",
        "        batchnorm = self._feature_blocks[0][1]\n",
        "        filters = convlayer.weight.data\n",
        "        scalars = (batchnorm.weight.data / torch.sqrt(batchnorm.running_var + 1e-05))\n",
        "        filters = (filters * scalars.view(-1, 1, 1, 1).expand_as(filters)).cpu().clone()\n",
        "\n",
        "        return filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc6wiq1qx_j0"
      },
      "source": [
        "And here it's the most important part of the code.\n",
        "\n",
        "We build the RotationPrediction Module.\n",
        "\n",
        "As in [1], we use the 'conv5' layer as representation features and a small classifier, as proposed in the paper.\n",
        "\n",
        "The key part is in the 'forward' function and in '_preprocess'.\n",
        "\n",
        "**Question**: complete the code XXXXXX in the '_preprocess' function. Remember that we are implementing the method of [1] as shown in the figure at the beginning of this TP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glv383BjZuYl"
      },
      "outputs": [],
      "source": [
        "class RotationPrediction(nn.Module):\n",
        "    metrics = ['Loss', 'Acc1']\n",
        "    metrics_fmt = [':.4e', ':6.2f']\n",
        "\n",
        "    def __init__(self, n_classes_classifier, device):\n",
        "        super().__init__()\n",
        "        self.device=device\n",
        "        self.model = AlexNet().to(self.device)\n",
        "        self.latent_dim = 256 * 13 * 13 # as defined in [1]\n",
        "        self.feat_layer = 'conv5' # as defined in [1]\n",
        "        self.n_classes_classifier = n_classes_classifier\n",
        "\n",
        "    # Same Classifier as defined in [1]\n",
        "    def construct_classifier(self):\n",
        "        classifier = nn.Sequential(\n",
        "            nn.AdaptiveMaxPool2d((6, 6)),\n",
        "            nn.BatchNorm2d(256, affine=False),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 6 * 6, self.n_classes_classifier)\n",
        "        )\n",
        "        classifier=classifier.to(self.device)\n",
        "        return classifier\n",
        "\n",
        "    def forward(self, images):\n",
        "        images=images.to(self.device)\n",
        "        batch_size = images.shape[0]\n",
        "\n",
        "        #images must have a torch.Size([batch_size, Channels, Height, Width])\n",
        "        #target must have a torch.Size([batch_size])\n",
        "        images, targets = self._preprocess(images)\n",
        "        targets = targets.to(self.device)\n",
        "\n",
        "        logits, zs = self.model(images, out_feat_keys=('classifier', self.feat_layer))\n",
        "        loss = F.cross_entropy(logits, targets).to(self.device)\n",
        "\n",
        "        pred = logits.argmax(dim=-1)\n",
        "        correct = pred.eq(targets).float().sum()\n",
        "        acc = correct / targets.shape[0] * 100.\n",
        "\n",
        "        zs = zs[:batch_size]\n",
        "        return dict(Loss=loss, Acc1=acc), zs[:batch_size]\n",
        "\n",
        "    def encode(self, images, flatten=True):\n",
        "        zs = self.model(images, out_feat_keys=(self.feat_layer,))\n",
        "        return zs.flatten(start_dim=1)\n",
        "\n",
        "    def _preprocess(self, images):\n",
        "        batch_size = images.shape[0]\n",
        "        # Remember that the rotations should be computed using only two operations...\n",
        "        XXXXXXXXXXXXXXXX\n",
        "        # These are the Images to Predict and must have a torch.Size([batch_size, Channels, Height, Width])\n",
        "        images_batch = XXXXXXXXXXXXXXXX\n",
        "        # Target are Labels $y$ and must have a torch.Size([batch_size])\n",
        "        targets = XXXXXXXXXXXXXXXX\n",
        "        return images_batch, targets\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hiFrDFlx_j1"
      },
      "source": [
        "Here we train our algorithm and evaluate its prediction power on a test set (function 'validate') using the function `accuracy`.\n",
        "\n",
        "**Question**: Do you understand what the function accuracy compute ? Explain what the output `res` contains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxeFKc9ObBT_"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(k=maxk, dim=1, largest=True, sorted=True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can define our train function. As you can see, we separately optimize the model $f$ and the classifier"
      ],
      "metadata": {
        "id": "1gl4kOVrY06V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, classifier, optimizer, optimizer_classifier, epoch, device):\n",
        "\n",
        "    model.train()\n",
        "    classifier.train()\n",
        "    top1=[]\n",
        "    top5=[]\n",
        "\n",
        "    for i, (images, target) in enumerate(train_loader):\n",
        "        # compute loss\n",
        "        bs = images.shape[0]\n",
        "        images = images.to(device)\n",
        "        target = target.to(device)\n",
        "        out, zs = model(images)\n",
        "        zs = zs.detach() # detach from the graph,  requires_grad = False\n",
        "\n",
        "        # compute optimizer step for ssl task using the previously defined Loss function of the model\n",
        "        optimizer.zero_grad()\n",
        "        out['Loss'].backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # compute loss\n",
        "        logits = classifier(zs)\n",
        "        loss = F.cross_entropy(logits, target)\n",
        "\n",
        "        # compute accuracy\n",
        "        acc1, acc5 = accuracy(logits, target, topk=(1, 5))\n",
        "        top1.append(acc1[0])\n",
        "        top5.append(acc5[0])\n",
        "\n",
        "        # computeoptimizer step for classifier using the cross entropy loss\n",
        "        optimizer_classifier.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_classifier.step()\n",
        "\n",
        "        #if i % 20 == 0:\n",
        "        #    print('Epoch {}, Iter: {} out of {}, Average loss: {:.4f}, acc 1: {:.4f}'.format(epoch, i, len(train_loader), loss / len(train_loader.dataset),acc1[0]))\n",
        "\n",
        "    print('Epoch: {}, Average loss: {:.4f}, Average acc 1: {:.4f}, Average acc 5: {:.4f}'.format(epoch, loss / len(train_loader.dataset),sum(top1)/len(top1), sum(top5)/len(top5)))\n",
        "    return sum(top1)/len(top1), sum(top5)/len(top5)"
      ],
      "metadata": {
        "id": "_0uXxqK2Y0GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptBnCRrIx_j1"
      },
      "source": [
        "Here, we define the:\n",
        "- DataLoader, a pytorch object that wraps an iterable around the Dataset to enable easy access to the samples duing training or validation\n",
        "- optimization process\n",
        "- the sceduler\n",
        "- all hyper-parameters (max epochs, batch size, lr, weight decay,etc.)\n",
        "\n",
        "Please note that it will lauch the training process. It can last some time... OR\n",
        "\n",
        "you can directly load a pre-trained model in the following cell !\n",
        "\n",
        "**Question**: what's the correct value for n_classes_classifier using the STL dataset ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OJUWIj6byHl"
      },
      "outputs": [],
      "source": [
        "maxepochs=50 # maximum number of epochs\n",
        "bs=128 # batch size\n",
        "lr_initial=0.01 # initial learning rate\n",
        "wd=5e-4 # weight decay\n",
        "n_classes_classifier = XXXXXXXXXXXXXXXX\n",
        "\n",
        "# Ensure that you are using GPU and all CPU workers\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "train_loader = data.DataLoader(train_dataset, batch_size=bs, num_workers=NUM_WORKERS, shuffle=True)\n",
        "\n",
        "model = RotationPrediction(n_classes_classifier=n_classes_classifier, device=device)\n",
        "classifier = model.construct_classifier()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr_initial, weight_decay=wd)\n",
        "optimizer_classifier = torch.optim.Adam(classifier.parameters(), lr=lr_initial)\n",
        "\n",
        "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=maxepochs)\n",
        "scheduler_classifier = lr_scheduler.CosineAnnealingLR(optimizer_classifier, T_max=maxepochs)\n",
        "\n",
        "top1Train=[]\n",
        "top5Train=[]\n",
        "\n",
        "for epoch in range(maxepochs):\n",
        "  top1Tr, top5Tr = train(train_loader, model, classifier, optimizer, optimizer_classifier, epoch, device)\n",
        "  top1Train.append(top1Tr)\n",
        "  top5Train.append(top5Tr)\n",
        "  scheduler.step()\n",
        "  scheduler_classifier.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEI93eHwx_j2"
      },
      "source": [
        "If you want to save your model, we can use torch.save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1CTc_Fyx_j2"
      },
      "outputs": [],
      "source": [
        "os.makedirs('models/', exist_ok=True)\n",
        "filename = 'models/checkpoint_rotation_50epochs.pth.tar'\n",
        "torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'state_dict': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'scheduler': scheduler.state_dict(),\n",
        "                'state_dict_classifier': classifier.state_dict(),\n",
        "                'optimizer_classifier': optimizer_classifier.state_dict(),\n",
        "                'schedular_classifier': scheduler_classifier.state_dict()\n",
        "            }, filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZYn94sOx_j3"
      },
      "source": [
        "If you want, here you can download the same model as before but already pre-trained for 50 epochs.\n",
        "\n",
        "It's important to set the 'model.eval()' since we want to evaluate it and not train it (no gradient is computed and parameters are not updated)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anFDU8S8x_j3"
      },
      "outputs": [],
      "source": [
        "os.makedirs('models/', exist_ok=True)\n",
        "# Download the Test set\n",
        "file_url = 'https://drive.google.com/uc?id=1ADslBKLjo1ulEfmz12ufEk2cjqnYJVRp'\n",
        "ckpt_pth = 'models/checkpoint_rotation_50epochs.pth.tar'\n",
        "gdown.download(file_url, ckpt_pth, quiet=True)\n",
        "n_classes_classifier = XXXXXXXXXXXXXXXX\n",
        "\n",
        "# Load checkpoint file of already trained model\n",
        "ckpt = torch.load(ckpt_pth)\n",
        "\n",
        "# Load Model parameters and set it into eval mode\n",
        "model_download = RotationPrediction(n_classes_classifier=n_classes_classifier, device=device)\n",
        "model_download.load_state_dict(ckpt['state_dict'])\n",
        "model_download.to(device)\n",
        "model_download.eval()\n",
        "\n",
        "# Load classifier model\n",
        "classifier_download = model_download.construct_classifier()\n",
        "classifier_download.load_state_dict(ckpt['state_dict_classifier'])\n",
        "classifier_download.to(device)\n",
        "classifier_download.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can test our model on the test set.\n",
        "\n",
        "**Question**: complete the code to compute average loss, average acc 1 and average acc 5 on the test set"
      ],
      "metadata": {
        "id": "j3kYqvVYkhhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(test_loader, model, classifier, device):\n",
        "    XXXXXXXXXXXXXXXX\n",
        "    return average_loss, average_acc1, average_acc5"
      ],
      "metadata": {
        "id": "CSRaqrG-i8cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs=128 # batch size\n",
        "\n",
        "test_loader = data.DataLoader(test_dataset, batch_size=bs, num_workers=NUM_WORKERS, shuffle=False, drop_last=False)\n",
        "\n",
        "# Choose either the model trained here or the downloaded model\n",
        "model_test=model\n",
        "#model_test=model_download\n",
        "\n",
        "classifier_test=classifier\n",
        "#classifier_test=classifier_download\n",
        "\n",
        "average_loss, average_acc1, average_acc5  = test(test_loader, model_test, classifier_test, device)"
      ],
      "metadata": {
        "id": "U0SFEYrzjYKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question**: are you satisfied with the obtained result ? If you had more time, what would you do to improve the results ?"
      ],
      "metadata": {
        "id": "4dvi4II2mI-w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WulgzY87x_j3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}